# Conditional GAN for Log-Mel Spectrogram & Audio Generation (PyTorch + Colab)

This project implements a Conditional GAN (cGAN) that generates *128Ã—512 log-mel spectrograms* conditioned on class labels, and reconstructs audio using *Inverse Mel + Griffin-Lim*.  
It is optimized for *Google Colab, **mixed precision (AMP), **pinned memory, and **fast spectrogram transforms*.

---

## âœ¨ Features

- *Conditional GAN (cGAN)* with label conditioning  
- *Log-Mel Spectrogram* generation (128Ã—512)  
- Optimized *Dataset loader* with pinned memory  
- *Mixed precision training (AMP)* using GradScaler  
- Automatic sample generation each epoch:
  - Spectrogram images saved to /gan_spectrogram_plots/
  - Reconstructed audio saved to /gan_generated_audio/
- Full compatibility with *Google Drive dataset storage*
- Automatic *waveform reconstruction* using:
  - InverseMelScale
  - GriffinLim

---

## ğŸ“ Project Structure


ğŸ“ project
â”‚â”€â”€ train.py
â”‚â”€â”€ README.md
â”‚â”€â”€ gan_generated_audio/
â”‚â”€â”€ gan_spectrogram_plots/
â”‚â”€â”€ drive/MyDrive/organized_dataset/train/class folders...


---

## ğŸ“¦ Installation

Install dependencies:


pip install torch torchvision torchaudio


If torchaudio is outdated:


pip install --pre torchaudio


---

## ğŸ“‚ Dataset Format

Dataset must be organized like:


organized_dataset/
   â””â”€â”€ train/
        â”œâ”€â”€ dog/
        â”‚     â”œâ”€â”€ file1.wav
        â”‚     â”œâ”€â”€ file2.wav
        â”œâ”€â”€ fire/
        â”‚     â”œâ”€â”€ file3.wav
        â”œâ”€â”€ rain/


Each folder represents a *sound category* used by the cGAN.

---

## â–¶ Google Drive Setup

The project automatically mounts Google Drive:

python
from google.colab import drive
drive.mount('/content/drive')


Dataset path:


drive/MyDrive/organized_dataset/train/


---

## ğŸ§  Model Overview

### ğŸ› Generator
- Input:
  - Random latent vector (size = 100)
  - One-hot label
- Output:
  - Log-Mel spectrogram of shape *(1 Ã— 128 Ã— 512)*
- Architecture:
  - Linear layer â†’ reshape â†’ series of ConvTranspose2D
  - ReLU activations

### ğŸ” Discriminator
- Input:
  - Spectrogram (1 Ã— 128 Ã— 512)
  - Label-embedded map (128 Ã— 512)
- Output:
  - Real/Fake score (patchGAN style)
- Architecture:
  - CNN layers with LeakyReLU activations

---

## ğŸµ Audio Reconstruction Pipeline

Generated log-mel â†’ mel â†’ inverse mel â†’ Griffin-Lim â†’ waveform


log_spec â†’ expm1() â†’ mel â†’ InverseMelScale â†’ GriffinLim â†’ audio.wav


Saved WAV files appear inside:


gan_generated_audio/


---

## ğŸš€ Training

Run:


python train.py


During training the script will:

### Every epoch:
âœ” generate spectrograms  
âœ” save images â†’ /gan_spectrogram_plots/epoch_XXX.png  
âœ” generate audio â†’ /gan_generated_audio/<class>_epX.wav  

---

## ğŸ“Š Training Parameters

| Parameter | Value |
|----------|--------|
| Latent dim | 100 |
| Batch size | 32 |
| Learning rate | 0.0002 |
| Epochs | 200 |
| Mel bins | 128 |
| Frames | 512 |
| AMP | Enabled |
| Optimizer | Adam (Î²=0.5, 0.999) |

---

## ğŸ“˜ Code Sections Summary

### 1. Dataset Loader  
- Loads WAV files  
- Converts to log-mel  
- Pads/truncates to 512 frames  
- Produces one-hot labels  

### 2. Generator & Discriminator  
- cGAN-based architecture  
- Label conditioning via concatenation & embedding  

### 3. Utility Functions  
- Spectrogram â†’ Audio  
- Audio saving + playback  
- Transform caching for speed  

### 4. Training Loop  
- AMP mixed precision  
- BCEWithLogitsLoss  
- Automatic generation + saving  

### 5. Main Execution  
- Loads categories from Drive  
- Creates DataLoader  
- Initializes models  
- Starts GAN training  

---

## ğŸ”® Future Upgrades

- Replace Griffin-Lim with *HiFi-GAN vocoder*
- Add WGAN-GP variant  
- Add attention-based generator  
- Support variable-length spectrograms  
- Add evaluation metrics (FID, IS for audio)  

---

## ğŸ¤ Contribution

Pull requests and improvements are welcome!

---

## â­ If this project helps you, please give the repo a star!